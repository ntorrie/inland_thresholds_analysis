---
title: "Flagging Inland Data - Explore Grossrange"
format:
  html:
    toc: true
    toc-depth: 3
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse) #todo: only load tidyverse packages you need
library(data.table)
library(qaqcmar)
library(here)
library(ggplot2)
library(sensorstrings)
library(summaryplots)
library(plotly)
library(DT)
library(leaflet)

# load CMAR river data
# uncleaned dataset with ALL inland data:
dat_all1 <- readRDS(here("data/2024-12-02_inland_data_raw.rds"))

# remove sissiboo river, hourglass lake, and piper lake data for now
remove_stations <- c("Hourglass Lake", "Sissiboo", "Piper Lake", "Mersey River 3")

dat_all <- dat_all1 %>%
  filter(!(station %in% remove_stations))

# clean dataset of select inland data from which to generate the thresholds:
dat_clean <- readRDS(here("data/2024-12-02_inland_data_prelim_qc_clean.rds"))

dat_clean_long <- ss_pivot_longer(dat_clean)

# generate station location dataset for threshold analysis
st_locations <- dat_clean %>%
  distinct(latitude, .keep_all = TRUE)

list <- unique(dat_all$station)

list2 <- unique(dat_clean$station)

dt_options <- list(
  dom = 'ft',
  paging = FALSE,
  searching = TRUE,
  scrollY = "500px",
  scrollX = "500px",
  columnDefs = list(list(className = 'dt-center', targets = "_all"))
)

thresholds_all <- thresholds

```


# Summary

CMAR has collected data on several inland bodies of freshwater in Nova Scotia, including lakes and rivers.

CMAR intends to process and publish all inland data under a new "Inland" branch of the [Coastal Monitoring Program](https://cmar.ca/coastal-monitoring-program/#station). Data will be processed in a similar manner to the coastal water quality data, and data flags will be applied using the [qaqcmar](https://github.com/dempsey-CMAR/qaqcmar) package. 

It is suspected that sensors on some rivers were out of the water for some period of time during the deployment due to low water levels. Data flagging efforts will flag data for periods of time sensors were suspected to be exposed. During the periods in which sensors were exposed to air, recorded temperatures fluctuate more quickly than when sensors are submerged. 

The purpose of this document is to help CMAR determine appropriate data flagging tests and thresholds for freshwater (inland) data. We do not currently have enough freshwater data to conduct as thorough an analysis as was done on the coastal water quality data to develop tests and thresholds, so thresholds may be picked in more subjective ways. Note, this initial threshold analysis has been completed on a subset of data.


##### Waterbodies included in threshold analysis:

```{r, echo = FALSE}
unique(dat_clean$waterbody)
```

##### Stations included in threshold analysis:

```{r, echo = FALSE}
unique(dat_clean$station)
```

##### Stations which may have experienced air exposure:

 - Liscomb 1
 - Liscomb 2
 - LaHave 2
 - Mersey 2
 - Tusket 3
 - Possibly Musquodoboit 1 and 2

# Data Visualization
## Station Locations

Approximate location of stations included in thresholds analysis.

```{r}
#| fig-height: 6

# interactive map
leaflet(st_locations) %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addCircleMarkers(
    data = st_locations,
    lng = ~longitude, lat = ~latitude, label = ~station,
    weight = 1,
    color = "black",
    fillOpacity = 0.75,
    radius = 5
  ) %>% 
  addScaleBar(
    position = "bottomleft", 
    options = scaleBarOptions(imperial = FALSE)
  ) %>%
  addProviderTiles("Esri.WorldTopoMap")
  #addProviderTiles(providers$CartoDB.Positron)

```


## Plot Uncleaned Station Data
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| results: asis
#| fig-height: 5

for (i in list2) {
  dat_i <- dat_all %>%
    filter(station == i)
  
  cat(paste("### ", i, "\n \n"))
  
  print(
    ggplot(
      dat_i,
      aes(x = timestamp_utc, y = temperature_degree_c, col = station)
    ) +
      geom_line(color = "black", linewidth = 0.75) +
      facet_grid(vars(station)) +
      ggtitle(i)
  )
  
  cat("\n\n")
}
```
:::

## Plot Cleaned Station Data

Suspected outliers have been removed from the following datasets:

 - Liscomb 1
 - Liscomb 2
 - LaHave 2
 - Mersey 2
 - Tusket 3
 
 The cleaned datasets will be used to generate the grossrange thresholds.

::: panel-tabset
```{r}
#| warning: false
#| message: false
#| results: asis
#| fig-height: 5

for (i in list2) {
  dat_i <- dat_clean %>%
    filter(station == i)
  
  cat(paste("### ", i, "\n \n"))
  
  print(
    ggplot(
      dat_i,
      aes(x = timestamp_utc, y = temperature_degree_c, col = station)
    ) +
      geom_point(color = "black") +
      facet_grid(vars(station)) +
     # facet_wrap(vars(station), ncol = 4) +
      ggtitle(i)
  )
  cat("\n\n")
}
```
:::

# Statistical Overview
## Distribution of Observations
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
p_i <- dat_clean %>%
  plot_histogram(hist_col = "temperature_degree_c", binwidth = 1) +
  scale_x_continuous("temperature_degree_c") +
  facet_wrap( ~ station, ncol = 2)

p_i

```

## Summary Stats
### By Station
```{r, echo = FALSE, warning = FALSE, message = FALSE}
stats <- dat_clean_long %>% 
  group_by(station, variable) %>% 
  summarise(
    n = n(),
    mean = round(mean(value), digits = 2),
    min = min(value),
    max = max(value),
    stdev = round(sd(value), digits = 2), 
    q_90 = round(quantile(value, probs = 0.90), digits = 2),
    q_95 = round(quantile(value, probs = 0.95), digits = 2),
    q_997 = round(quantile(value, probs = 0.997), digits = 2)
  ) %>%
  ungroup() %>% 
  mutate(n_percent = round(n * 100 / sum(n), digits = 1)) %>% 
  select(station, variable, n, n_percent, everything())


stats %>%
  datatable(rownames = FALSE, options = dt_options)
```

### Pooled
```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.height = 7}
stats_all <- dat_clean_long %>% 
  summarise(
    n = n(),
    mean = round(mean(value), digits = 2),
    min = min(value),
    max = max(value),
    stdev = round(sd(value), digits = 2), 
    q_90 = round(quantile(value, probs = 0.90), digits = 2),
    q_95 = round(quantile(value, probs = 0.95), digits = 2),
    q_997 = round(quantile(value, probs = 0.997), digits = 2)
  ) %>%
  mutate(n_percent = round(n * 100 / sum(n), digits = 1))  


stats_all %>%
  datatable(rownames = FALSE, options = dt_options)
```

## Mean and Standard Deviation
```{r}
#| warning: false
#| message: false
#| results: asis
#| fig-height: 8

p <- ggplot(
      stats,
      aes(mean, reorder(station, mean), col = mean,
          text = paste("station: ", station, "\nmean: ", mean))
      ) +
      scale_y_discrete(name = "")

p + geom_point(size = 4) +
    geom_errorbar(
      aes(xmin = mean - stdev, xmax = mean + stdev), width = 0
    ) +
    scale_x_continuous("mean +/- standard deviation") +
    theme(
      text = element_text(size = 14),
      legend.position = "none"
    )

```

## Quantiles
```{r}
#| warning: false
#| message: false
#| results: asis
#| fig-height: 8

stats_quantile <- stats %>%
  select(station, contains("q")) %>%
  pivot_longer(cols = contains("q"), names_to = "quantile")

p <- ggplot(stats_quantile,
            aes(quantile, value, group = station, col = station)) +
  geom_point() +
  geom_line() 

p

```


# Calculate user grossrange threshold

Since the datasets are all normally distributed, **mean + 3SD** will be used to develop the grossrange thresholds. Stations have similar mean + SD, so data has been pooled to determine one set of user grossrange thresholds to be used to flag all inland river datasets.

Note, the statistically derived thresholds may be misleading when applied to future datasets, because most of the training datasets do not include data from the full year. Very few of our inland datasets include data from winter months. Thus, for now it is recommended that CMAR user grossrange thresholds are ONLY applied to data collected between June and October (inclusive).

## Mean_sd threshold table
```{r, echo = FALSE, warning = FALSE, fig.height = 5}
#look at histograms of SD roll colums
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed

#calculate threshold using clean data
thresh_user <- qc_calculate_user_thresholds(dat_clean, temperature_degree_c, n_sd = 3, keep_stats = FALSE)

thresh_user %>%
  datatable(rownames = FALSE, options = dt_options)

#manually update threshold table found at: here("thresholds_inland.csv")
#read in threshold table
thresholds <- read.csv(here("thresholds_inland.csv"))

```


# Apply user grossrange threshold
## Visualize flagged data - threshold subset
Flag datasets included in threshold analysis.

::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5

for (i in list2) {

  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))

county_i <- dat_i$county[1]

qc_i <- qc_test_grossrange(dat_i)

#plot
qc_long_i <- qc_pivot_longer(qc_i, qc_tests = "grossrange")
p <- qc_plot_flags(qc_long_i, qc_tests = "grossrange", var = "temperature_degree_c")
print(p$temperature_degree_c$grossrange)


cat("\n\n")
}



```
::: 

## Visualize flagged data - all datasets
Flag **all** inland datasets

::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5

for (i in list) {

  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))

county_i <- dat_i$county[1]

qc_i <- qc_test_grossrange(dat_i)

#plot
qc_long_i <- qc_pivot_longer(qc_i, qc_tests = "grossrange")
p <- qc_plot_flags(qc_long_i, qc_tests = "grossrange", var = "temperature_degree_c")
print(p$temperature_degree_c$grossrange)


cat("\n\n")
}
```
:::
