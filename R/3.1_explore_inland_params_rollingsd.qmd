---
title: "Flagging Inland Data - Explore Rolling SD"
format:
  html:
    toc: true
    toc-depth: 3
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse) #todo: only load tidyverse packages you need
library(data.table)
library(qaqcmar)
library(here)
library(ggplot2)
library(sensorstrings)
library(summaryplots)
library(plotly)
library(DT)
library(leaflet)
library(zoo)
library(purrr)

# load CMAR river data
# uncleaned dataset with ALL inland data:
dat_all1 <- readRDS(here("data/2024-12-02_inland_data_raw.rds"))

# remove sissiboo river, hourglass lake, piper lake and Mersey River 3 data for now
remove_stations <- c("Hourglass Lake", "Sissiboo", "Piper Lake", "Mersey River 3")

dat_all <- dat_all1 %>%
  filter(!(station %in% remove_stations))

# clean dataset of select inland data from which to generate the thresholds:
dat_clean <- readRDS(here("data/2024-12-02_inland_data_prelim_qc_clean.rds"))

dat_clean_long <- ss_pivot_longer(dat_clean)

# generate station location dataset for threshold analysis
st_locations <- dat_clean %>%
  distinct(latitude, .keep_all = TRUE)

list <- unique(dat_all$station)

list2 <- unique(dat_clean$station)

dt_options <- list(
  dom = 'ft',
  paging = FALSE,
  searching = TRUE,
  scrollY = "500px",
  scrollX = "500px",
  columnDefs = list(list(className = 'dt-center', targets = "_all"))
)


period_hours <- 24
max_interval_hours <- 2
align_window <- "center"

dat_clean_roll <- dat_clean_long %>%
  group_by(station,
           deployment_range,
           sensor_serial_number,
           variable) %>%
  dplyr::arrange(timestamp_utc, .by_group = TRUE) %>%
  mutate(
    # sample interval
    int_sample = difftime(timestamp_utc, lag(timestamp_utc), units = "mins"),
    int_sample = round(as.numeric(int_sample)),

    # number of samples in  period_hours
    # 60 mins / hour * 1 sample / int_sample mins * 24 hours / period
    n_sample = round((60 / int_sample) * period_hours),
    # n_sample = if_else(is.na(n_sample), 1, n_sample), # first obs
    n_sample_effective = case_when(
      # first observation of each group is NA, which will give error in rollapply
      is.na(n_sample) ~ 0,
      # if the sample interval is greater than acceptable limit, set n_sample to 0
      # so that roll_sd will be NA
      int_sample > max_interval_hours * 60 ~ 0,
      TRUE ~ n_sample
    ),
    # rolling sd
    sd_roll = rollapply(
      value,
      width = n_sample_effective,
      align = align_window,
      FUN = sd,
      fill = NA
    ),
    sd_roll = round(sd_roll, digits = 2)
  )

thresholds_all <- thresholds

```


# Summary

CMAR has collected data on several inland bodies of freshwater in Nova Scotia, including lakes and rivers.

CMAR intends to process and publish all inland data under a new "Inland" branch of the [Coastal Monitoring Program](https://cmar.ca/coastal-monitoring-program/#station). Data will be processed in a similar manner to the coastal water quality data, and data flags will be applied using the [qaqcmar](https://github.com/dempsey-CMAR/qaqcmar) package. 

It is suspected that sensors on some rivers were out of the water for some period of time during the deployment due to low water levels. Data flagging efforts will flag data for periods of time sensors were suspected to be exposed. During the periods in which sensors were exposed to air, recorded temperatures fluctuate more quickly than when sensors are submerged. 

The purpose of this document is to help CMAR determine appropriate data flagging tests and thresholds for freshwater (inland) data. We do not currently have enough freshwater data to conduct as thorough an analysis as was done on the coastal water quality data to develop tests and thresholds, so thresholds may be picked in more subjective ways. Note, this initial threshold analysis has been completed on a subset of data.



##### Waterbodies included in threshold analysis:

```{r, echo = FALSE}
unique(dat_clean$waterbody)
```

##### Stations included in threshold analysis:

```{r, echo = FALSE}
unique(dat_clean$station)
```

##### Stations which may have experienced air exposure:

 - Liscomb 1
 - Liscomb 2
 - LaHave 2
 - Mersey 2
 - Tusket 3
 - Possibly Musquodoboit 1 and 2

# Data visualization
## Station locations

Approximate location of stations included in threshold analysis.

```{r}
#| fig-height: 6

# interactive map
leaflet(st_locations) %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addCircleMarkers(
    data = st_locations,
    lng = ~longitude, lat = ~latitude, label = ~station,
    weight = 1,
    color = "black",
    fillOpacity = 0.75,
    radius = 5
  ) %>% 
  addScaleBar(
    position = "bottomleft", 
    options = scaleBarOptions(imperial = FALSE)
  ) %>%
  addProviderTiles("Esri.WorldTopoMap")
  #addProviderTiles(providers$CartoDB.Positron)

```


## Plot uncleaned station data

::: panel-tabset
```{r}
#| warning: false
#| message: false
#| results: asis
#| fig-height: 5

for (i in list2) {
  dat_i <- dat_all %>%
    filter(station == i)
  
  cat(paste("### ", i, "\n \n"))
  
  print(
    ggplot(
      dat_i,
      aes(x = timestamp_utc, y = temperature_degree_c, col = station)
    ) +
      geom_line(color = "black", linewidth = 0.75) +
      facet_grid(vars(station)) +
      ggtitle(i)
  )
  
  cat("\n\n")
}
```
:::

# Plot cleaned station data

Suspected outliers have been removed from the following datasets:

 - Liscomb 1
 - Liscomb 2
 - LaHave 2
 - Mersey 2
 - Tusket 3
 
The cleaned datasets will be used to generate the grossrange thresholds.

::: panel-tabset
```{r}
#| warning: false
#| message: false
#| results: asis
#| fig-height: 5

for (i in list2) {
  dat_i <- dat_clean %>%
    filter(station == i)
  
  cat(paste("### ", i, "\n \n"))
  
  print(
    ggplot(
      dat_i,
      aes(x = timestamp_utc, y = temperature_degree_c, col = station)
    ) +
      geom_point(color = "black") +
      facet_grid(vars(station)) +
     # facet_wrap(vars(station), ncol = 4) +
      ggtitle(i)
  )
  cat("\n\n")
}
```
:::

# Statistical overview
## Distribution of sd_roll
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#| fig-cap: Distribution of temperature observations by station (binwidth = 0.25 degree c).
p_i <- dat_clean_roll %>%
  plot_histogram(hist_col = "sd_roll", binwidth = 0.25) +
  scale_x_continuous("sd_roll") +
  facet_wrap( ~ station, ncol = 2)

p_i

```

## Distribution all
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#| fig-height: 6
#| fig-cap: Distribution of all temperature observations (binwidth = 0.25 degree c).

p_j <- dat_clean_roll %>%
  plot_histogram(hist_col = sd_roll, binwidth = 0.25) +
  scale_x_continuous("sd_roll")

p_j

```

# Calculate rolling standard deviation thresholds

Compare various methods for calculating thresholds.

::: panel-tabset
## Mean_sd threshold table
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#look at histograms of SD roll columns
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed


thresh_sd <- qc_calculate_rolling_sd_thresholds(dat_clean_roll, temperature_degree_c, stat = "mean_sd", n_sd = 3)

thresh_sd %>%
  datatable(rownames = FALSE, options = dt_options)


```

## Quartile threshold table
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#look at histograms of SD roll columns
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed

thresh_quartile <- qc_calculate_rolling_sd_thresholds(dat_clean_roll, temperature_degree_c, stat = "quartile", prob = 0.97)

thresh_quartile %>%
  datatable(rownames = FALSE, options = dt_options)

```

## Quartile pooled threshold table prob = 0.95
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#look at histograms of SD roll columns
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed
thresh_quartile_pooled_95 <- dat_clean_roll %>%
  dplyr::group_by(variable) %>%
  qc_calculate_rolling_sd_thresholds(temperature_degree_c, stat = "quartile", prob = 0.95)

thresh_quartile_pooled_95 %>%
  datatable(rownames = FALSE, options = dt_options)

```

## Quartile pooled threshold table prob = 0.97
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#look at histograms of SD roll columns
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed
thresh_quartile_pooled_97 <- dat_clean_roll %>%
  dplyr::group_by(variable) %>%
  qc_calculate_rolling_sd_thresholds(temperature_degree_c, stat = "quartile", prob = 0.97)

thresh_quartile_pooled_97 %>%
  datatable(rownames = FALSE, options = dt_options)

```

## Quartile pooled threshold table prob = 0.99
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#look at histograms of SD roll columns
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed
thresh_quartile_pooled_99 <- dat_clean_roll %>%
  dplyr::group_by(variable) %>%
  qc_calculate_rolling_sd_thresholds(temperature_degree_c, stat = "quartile", prob = 0.99)

thresh_quartile_pooled_99 %>%
  datatable(rownames = FALSE, options = dt_options)

```

## Quartile pooled threshold table prob = 0.997
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#look at histograms of SD roll columns
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed
thresh_quartile_pooled_997 <- dat_clean_roll %>%
  dplyr::group_by(variable) %>%
  qc_calculate_rolling_sd_thresholds(temperature_degree_c, stat = "quartile", prob = 0.997)

thresh_quartile_pooled_997 %>%
  datatable(rownames = FALSE, options = dt_options)

```
:::

# Visualize flagged data
Visualize data flagged using various methods, to determine which method produces the best results. This time the thresholds have been applied to all of the inland datasets, not just the cleaned ones used to generate the thresholds.

## Mean_sd
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5


for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))

county_i <- dat_i$county[1]


thresholds <- thresholds_all %>% 
  filter(qc_test == c("rolling_sd"), variable == "temperature_degree_c", county == county_i) 

thresholds$threshold_value = mean(thresh_sd$threshold_value)

  
#apply test
qc_i <- qc_test_rolling_sd(dat_i, county = county_i)

#plot
qc_long_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc_long_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}

```
::: 


## Quartile
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5


for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))

county_i <- dat_i$county[1]


thresholds <- thresholds_all %>% 
  filter(qc_test == c("rolling_sd"), variable == "temperature_degree_c", county == county_i) 

thresholds$threshold_value = mean(thresh_quartile$threshold_value)
  
#apply test
qc_i <- qc_test_rolling_sd(dat_i, county = county_i)

#plot
qc_long_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc_long_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}

```
:::


## Quartile pooled 0.95
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5


for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))

county_i <- dat_i$county[1]

thresholds <- thresholds_all %>% 
  filter(qc_test == c("rolling_sd"), variable == "temperature_degree_c", county == county_i) 

thresholds$threshold_value = thresh_quartile_pooled_95$threshold_value
  
  
#apply test
qc_i <- qc_test_rolling_sd(dat_i, county = county_i)

#plot
qc_long_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc_long_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}

```
:::

## Quartile pooled 0.97
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5

for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))

county_i <- dat_i$county[1]

thresholds <- thresholds_all %>% 
  filter(qc_test == c("rolling_sd"), variable == "temperature_degree_c", county == county_i) 

thresholds$threshold_value = thresh_quartile_pooled_97$threshold_value
  
  
#apply test
qc_i <- qc_test_rolling_sd(dat_i, county = county_i)

#plot
qc_long_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc_long_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}

```
:::

## Quartile pooled 0.99
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5

for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))

county_i <- dat_i$county[1]

thresholds <- thresholds_all %>% 
  filter(qc_test == c("rolling_sd"), variable == "temperature_degree_c", county == county_i) 

thresholds$threshold_value = thresh_quartile_pooled_99$threshold_value
  
  
#apply test
qc_i <- qc_test_rolling_sd(dat_i, county = county_i)

#plot
qc_long_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc_long_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}

```
:::

## Quartile pooled 0.997
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5

for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))

county_i <- dat_i$county[1]

thresholds <- thresholds_all %>% 
  filter(qc_test == c("rolling_sd"), variable == "temperature_degree_c", county == county_i) 

thresholds$threshold_value = thresh_quartile_pooled_997$threshold_value
  
  
#apply test
qc_i <- qc_test_rolling_sd(dat_i, county = county_i)

#plot
qc_long_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc_long_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}

```
:::



# Apply rolling SD threshold
## Visualize flagged data - all datasets
Due to the right-skew of the sd_roll distribution plots, the quantile method was used to establish thresholds. Because the overall distribution of the data was relatively similar for each station, data has been pooled to determine one rolling standard deviation threshold to be used to flag all inland datasets.

The final threshold value chosen was **q99.7: 2.04**

::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5

#make changes to threshold .csv manually if needed
#read in inland thresholds table
thresholds <- read.csv(here("thresholds_inland.csv"))

summary_stats_list <- list()


for (i in list) {

  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))

county_i <- dat_i$county[1]

qc_i <- qc_test_rolling_sd(dat_i)

#percent observations flagged
summary_i <- qc_i %>%
  group_by(station) %>%
  summarise(
    n_obs = n(),
    n_suspect = sum(rolling_sd_flag_temperature_degree_c == 3)
  ) %>%
  mutate(percent_suspect = round((100 * n_suspect / n_obs), digits = 3)) %>%
  mutate(threshold = 2.04) %>%
  mutate(q = "q99.7") %>%
  ungroup()

summary_stats_list[[i]] <- summary_i

#plot
qc_long_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc_long_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}



```
::: 

## Rolling SD flag summary table
```{r}
summary_stats_table <- summary_stats_list %>%
  map_df(rbind) %>%
  datatable(rownames = FALSE, options = dt_options)

summary_stats_table
```



