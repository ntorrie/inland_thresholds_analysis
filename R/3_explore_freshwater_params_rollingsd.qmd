---
title: "Flagging Inland Data - Rolling SD"
format:
  html:
    toc: true
    toc-depth: 3
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(data.table)
library(qaqcmar)
library(here)
library(ggplot2)
library(sensorstrings)
library(summaryplots)
library(plotly)
library(DT)
library(leaflet)
library(zoo)

#Load CMAR river data
dat_all <- readRDS(here("data/2024-09-05_inland_data_prelim_qc.rds"))

dat_clean <- readRDS(here("data/2024-09-05_inland_data_prelim_qc_clean.rds"))

dat_long <- ss_pivot_longer(dat_clean)


st_locations <- dat_all %>%
  distinct(latitude, .keep_all = TRUE)

list <- unique(dat_all$station)

list2 <- unique(dat_clean$station)

dt_options <- list(
  dom = 'ft',
  paging = FALSE,
  searching = TRUE,
  scrollY = "500px",
  scrollX = "500px",
  columnDefs = list(list(className = 'dt-center', targets = "_all"))
)



period_hours <- 24
max_interval_hours <- 2
align_window <- "center"

dat_clean_roll <- dat_long %>%
  group_by(station,
           deployment_range,
           sensor_serial_number,
           variable) %>%
  dplyr::arrange(timestamp_utc, .by_group = TRUE) %>%
  mutate(
    # sample interval
    int_sample = difftime(timestamp_utc, lag(timestamp_utc), units = "mins"),
    int_sample = round(as.numeric(int_sample)),

    # number of samples in  period_hours
    # 60 mins / hour * 1 sample / int_sample mins * 24 hours / period
    n_sample = round((60 / int_sample) * period_hours),
    # n_sample = if_else(is.na(n_sample), 1, n_sample), # first obs
    n_sample_effective = case_when(
      # first observation of each group is NA, which will give error in rollapply
      is.na(n_sample) ~ 0,
      # if the sample interval is greater than acceptable limit, set n_sample to 0
      # so that roll_sd will be NA
      int_sample > max_interval_hours * 60 ~ 0,
      TRUE ~ n_sample
    ),
    # rolling sd
    sd_roll = rollapply(
      value,
      width = n_sample_effective,
      align = align_window,
      FUN = sd,
      fill = NA
    ),
    sd_roll = round(sd_roll, digits = 2)
  )



```

# Inland Parameters: Explore Thresholds

## Summary

CMAR has collected data on several inland bodies of freshwater in Nova Scotia through the wild Atlantic salmon river monitoring project. In addition, CMAR has data collected on several freshwater lakes (e.g. Piper Lake), which is currently published through the Water Quality branch of the [Coastal Monitoring Program](https://cmar.ca/coastal-monitoring-program/#station). 

CMAR intends to process and republish all inland data under a new "Inland" branch of the Coastal Monitoring Program. Data will be processed in a similar manner to the water quality data, and data flags will be applied using the [qaqcmar](https://github.com/dempsey-CMAR/qaqcmar) package. 

It is suspected that sensors on some rivers were out of the water for some period of time during the deployment. Data flagging efforts will flag data for periods of time sensors were suspected to be exposed. During the periods in which sensors were exposed to air, recorded temperatures fluctuate more quickly than when sensors are submerged. 

The purpose of this document is to help CMAR determine appropriate data flagging tests and thresholds for freshwater (inland) data. We do not currently have enough freshwater data to conduct as thorough an analysis as was done on the saltwater water quality data to develop tests and thresholds, so thresholds may be picked in more subjective ways.



##### Waterbodies in dataset:

```{r, echo = FALSE}
unique(dat_all$waterbody)
```

##### Stations in dataset:

```{r, echo = FALSE}
unique(dat_all$station)
```

##### Stations which may have experienced air exposure:

 - Liscomb 1
 - Liscomb 2
 - LaHave 2
 - Mersey 2
 - Tusket 3
 - Possibly Musquodoboit 1 and 2

# Station Locations

Approximate location of stations included in analysis.

```{r}
#| fig-height: 6

# interactive map
leaflet(st_locations) %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addCircleMarkers(
    data = st_locations,
    lng = ~longitude, lat = ~latitude, label = ~station,
    weight = 1,
    color = "black",
    fillOpacity = 0.75,
    radius = 5
  ) %>% 
  addScaleBar(
    position = "bottomleft", 
    options = scaleBarOptions(imperial = FALSE)
  ) %>%
  addProviderTiles("Esri.WorldTopoMap")
  #addProviderTiles(providers$CartoDB.Positron)

```


# Plot all Station Data

::: panel-tabset
```{r}
#| warning: false
#| message: false
#| results: asis
#| fig-height: 5

for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
  cat(paste("### ", i, "\n \n"))
  
  print(
    ggplot(
      dat_i,
      aes(x = timestamp_utc, y = temperature_degree_c, col = station)
    ) +
      geom_line(color = "black", linewidth = 0.75) +
      facet_grid(vars(station)) +
      ggtitle(i)
  )
  
  cat("\n\n")
}
```
:::

# Plot Cleaned Station Data

Suspected outliers have been removed from the following datasets:

 - Liscomb 1
 - Liscomb 2
 - LaHave 2
 - Mersey 2
 - Tusket 3

::: panel-tabset
```{r}
#| warning: false
#| message: false
#| results: asis
#| fig-height: 5

for (i in list2) {
  dat_i <- dat_clean %>%
    filter(station == i)
  
  cat(paste("### ", i, "\n \n"))
  
  print(
    ggplot(
      dat_i,
      aes(x = timestamp_utc, y = temperature_degree_c, col = station)
    ) +
      geom_point(color = "black") +
      facet_grid(vars(station)) +
     # facet_wrap(vars(station), ncol = 4) +
      ggtitle(i)
  )
  cat("\n\n")
}
```
:::

# Distribution plots
## Distribution of sd_roll
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#| fig-cap: Distribution of temperature observations by station (binwidth = 0.25 degree c).
p_i <- dat_clean_roll %>%
  plot_histogram(hist_col = "sd_roll", binwidth = 0.25) +
  scale_x_continuous("sd_roll") +
  facet_wrap( ~ station, ncol = 2)

p_i

```

## Distribution all
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#| fig-height: 6
#| fig-cap: Distribution of temperature observations (binwidth = 0.25 degree c).

p_j <- dat_clean_roll %>%
  plot_histogram(hist_col = sd_roll, binwidth = 0.25) +
  scale_x_continuous("sd_roll")

p_j

```

# Apply Thresholds

::: panel-tabset
## Mean_sd threshold table
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#look at histograms of SD roll columns
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed


thresh_sd <- qc_calculate_rolling_sd_thresholds(dat_clean_roll, temperature_degree_c, stat = "mean_sd", n_sd = 3)

thresh_sd %>%
  datatable(rownames = FALSE, options = dt_options)


```

## Quartile threshold table
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#look at histograms of SD roll columns
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed

thresh_quartile <- qc_calculate_rolling_sd_thresholds(dat_clean_roll, temperature_degree_c, stat = "quartile", prob = 0.97)

thresh_quartile %>%
  datatable(rownames = FALSE, options = dt_options)

```

## Quartile pooled threshold table prob = 0.95
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#look at histograms of SD roll columns
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed
thresh_quartile_pooled_95 <- dat_clean_roll %>%
  dplyr::group_by(county) %>%
  qc_calculate_rolling_sd_thresholds(temperature_degree_c, stat = "quartile", prob = 0.95)

thresh_quartile_pooled_95 %>%
  datatable(rownames = FALSE, options = dt_options)

```

## Quartile pooled threshold table prob = 0.97
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#look at histograms of SD roll columns
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed
thresh_quartile_pooled_97 <- dat_clean_roll %>%
  dplyr::group_by(county) %>%
  qc_calculate_rolling_sd_thresholds(temperature_degree_c, stat = "quartile", prob = 0.97)

thresh_quartile_pooled_97 %>%
  datatable(rownames = FALSE, options = dt_options)

```

## Quartile pooled threshold table prob = 0.99
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#look at histograms of SD roll columns
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed
thresh_quartile_pooled_99 <- dat_clean_roll %>%
  dplyr::group_by(county) %>%
  qc_calculate_rolling_sd_thresholds(temperature_degree_c, stat = "quartile", prob = 0.99)

thresh_quartile_pooled_99 %>%
  datatable(rownames = FALSE, options = dt_options)

```

## Quartile pooled threshold table prob = 0.997
```{r, echo = FALSE, warning = FALSE, fig.height = 15}
#look at histograms of SD roll columns
#calculate thresholds by quantiles if skewed, mean/sd if normally distributed
thresh_quartile_pooled_997 <- dat_clean_roll %>%
  dplyr::group_by(county) %>%
  qc_calculate_rolling_sd_thresholds(temperature_degree_c, stat = "quartile", prob = 0.997)

thresh_quartile_pooled_997 %>%
  datatable(rownames = FALSE, options = dt_options)

```
:::

# Visualize flagged data
## Mean_sd
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5
threshold_value_sd <- mean(thresh_sd$threshold_value)

newrow_sd <- list(qc_test = "rolling_sd",
                  variable = "temperature_degree_c",
                  county = "river_data",
                  month = "NA",
                  sensor_type = "NA",
                  threshold = "rolling_sd_max",
                  threshold_value = threshold_value_sd)

thresholds <- thresholds %>% 
  filter(qc_test == c("rolling_sd"), variable == "temperature_degree_c") %>%
  rbind(newrow_sd)

for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))
  
#apply test
qc_i <- qc_test_rolling_sd(dat_i, county = "river_data")

#plot
qc2_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc2_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}

```
::: 


## Quartile
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5

threshold_value <- mean(thresh_quartile$threshold_value)

#update threshold value in thresholds table. Caution - hard coded in. Check this!
thresholds[16,7] = threshold_value

for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))
  
#apply test
qc_i <- qc_test_rolling_sd(dat_i, county = "river_data")

#plot
qc2_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc2_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}

```
:::


## Quartile Pooled 0.95
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5

threshold_value <- thresh_quartile_pooled_95$threshold_value

#update threshold value in thresholds table. Caution - hard coded in. Check this!
thresholds[16,7] = threshold_value

for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))
  
#apply test
qc_i <- qc_test_rolling_sd(dat_i, county = "river_data")

#plot
qc2_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc2_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}

```
:::

## Quartile Pooled 0.97
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5

threshold_value <- thresh_quartile_pooled_97$threshold_value

#update threshold value in thresholds table. Caution - hard coded in. Check this!
thresholds[16,7] = threshold_value

for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))
  
#apply test
qc_i <- qc_test_rolling_sd(dat_i, county = "river_data")

#plot
qc2_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc2_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}

```
:::

## Quartile Pooled 0.99
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5

threshold_value <- thresh_quartile_pooled_99$threshold_value

#update threshold value in thresholds table. Caution - hard coded in. Check this!
thresholds[16,7] = threshold_value

for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))
  
#apply test
qc_i <- qc_test_rolling_sd(dat_i, county = "river_data")

#plot
qc2_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc2_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}

```
:::

## Quartile Pooled 0.997
::: panel-tabset
```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5

threshold_value <- thresh_quartile_pooled_997$threshold_value

#update threshold value in thresholds table. Caution - hard coded in. Check this!
thresholds[16,7] = threshold_value

for (i in list) {
  dat_i <- dat_all %>%
    filter(station == i)
  
cat(paste("### ", i, "\n \n"))
  
#apply test
qc_i <- qc_test_rolling_sd(dat_i, county = "river_data")

#plot
qc2_i <- qc_pivot_longer(qc_i, qc_tests = "rolling_sd")
p <- qc_plot_flags(qc2_i, qc_tests = "rolling_sd", var = "temperature_degree_c")
print(p$temperature_degree_c$rolling_sd)


cat("\n\n")
}

```
:::



# Apply test
Due to the right-skew of the sd_roll distribution plots, the quantile method was used to establish thresholds. Because the overall distribution of the data was relatively the same for each station, all station data was pooled before determining a threshold and applying the test.

```{r}
#| warning: false
#| message: false
#| echo: false
#| results: asis
#| fig-height: 5

threshold_value <- thresh_quartile_pooled_997$threshold_value

q = "q_997"

thresholds[16,7] = threshold_value

sd_roll_applied_all <- qc_test_rolling_sd(dat_all, county = "river_data")


#percent observations flagged
summary_all <- sd_roll_applied_all %>%
  group_by(station) %>%
  summarise(
    n_obs = n(),
    n_suspect = sum(rolling_sd_flag_temperature_degree_c == 3)
  ) %>%
  mutate(percent_suspect = round((100 * n_suspect / n_obs), digits = 3)) %>%
  mutate(threshold = threshold_value) %>%
  mutate(q = q) %>%
  ungroup()



summary_all %>%
  datatable(rownames = FALSE, options = dt_options)

saveRDS(sd_roll_applied_all, here("data/2024-10-18_inland_data_flagged_all.rds"))

```



```{r}
#remove flagged values
flagged_dat_all <- sd_roll_applied_all %>%
  filter(rolling_sd_flag_temperature_degree_c <2)

saveRDS(flagged_dat_all, here("data/2024-10-18_inland_data_flagged_rm_all.rds"))
```


## Plot Flagged/Cleaned Station Data

::: panel-tabset
```{r}
#| warning: false
#| message: false
#| results: asis
#| fig-height: 5

for (i in list) {
  dat_i <- flagged_dat_all %>%
    filter(station == i)
  
  cat(paste("### ", i, "\n \n"))
  
  print(
    ggplot(
      dat_i,
      aes(x = timestamp_utc, y = temperature_degree_c, col = station)
    ) +
      geom_point(color = "black") +
      facet_grid(vars(station)) +
      ggtitle(i)
  )
  
  cat("\n\n")
}
```
:::
